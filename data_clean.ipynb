{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_report_oi = './reports/oferta_individual.xlsx'\n",
    "path_portafolio = './reports/portafolio.xlsx'\n",
    "path_past_portafolio = './reports/past_portafolio.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista de campos que se usarán del reporte estadístico de Hércules.\n",
    "fields_report = [\n",
    "    'Evento',\n",
    "    'Documento',\n",
    "    'Tipo Documento',\n",
    "    'Sedes',\n",
    "    'Área',\n",
    "    'Ciclos',\n",
    "    'Categoría Deportiva',\n",
    "    'Nivel',\n",
    "    'Género',\n",
    "    'Categoría Precio',\n",
    "    'Categoría Afiliación',\n",
    "    'creada_por',\n",
    "    'Estado Cotización',\n",
    "    'Canal de Pago',\n",
    "    'Canal de Cotización',\n",
    "    'Forma de Pago',\n",
    "    'Franquicias',\n",
    "    'Precio Base',\n",
    "    'Costo',\n",
    "    'Tarifa Plena',\n",
    "    'Subsidio a la Demanda',\n",
    "    'Identificador del Cajero',\n",
    "    'Identificador Máquina',\n",
    "    'Fecha Registro',\n",
    "    'Documento Titular',\n",
    "    'Fecha Cotización',\n",
    "    'Id Material',\n",
    "    'Fecha Inicio del Servicio',\n",
    "    'Fecha Fin del Servicio',\n",
    "    'Id Servicio',\n",
    "    'Edad',\n",
    "    'Fecha de Nacimiento',\n",
    "    'Valor',\n",
    "    'Motivo de Cambio',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando la data desde el reporte.\n",
    "dataset=pd.read_excel(path_report_oi, usecols=fields_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han eliminado 112 filas que no tienen registros para las sedes o en la fecha de reserva.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75773/1385572998.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_75773/1385572998.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se eliminan todos los registros donde no haya un valor en la sede o en la fecha de reserva.\n",
    "dash_dataset = dataset.dropna(subset=['Sedes', 'Fecha Inicio del Servicio'])\n",
    "print(f\"Se han eliminado {dataset['Evento'].count()-dash_dataset['Evento'].count()} filas que no tienen registros en las sedes o en la fecha de reserva.\")\n",
    "\n",
    "\n",
    "# Inserción de columna 'Tipo de Oferta' al final del dataset, asignádole un valor ''.\n",
    "dash_dataset.insert(loc=len(dash_dataset.columns), column='Tipo de Oferta', value='')\n",
    "\n",
    "# Eliminación del prefijo '-F' en los código SAP (campo 'Id Material') de la oferta FOSFEC.\n",
    "dash_dataset['Id Material'].replace(r'(\\d{8})-F', r'\\g<1>', inplace=True, regex=True)\n",
    "dash_dataset['Id Material'] = pd.to_numeric(dash_dataset['Id Material'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patrones empleados en el campo 'Motivo de cambio' usando RegEx y con ello asignar las ofertas por Excedentes del 55% y cobro a empresas por una venta individual.\n",
    "pat_exc55 = r'exc\\w*\\s*\\d*[%]*[^excel]'\n",
    "pat_empresarial = r'empr\\w*\\s*|conv\\w*\\s*|nit\\s*\\d*|contr|se factura'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignación tipo de oferta 'Pago con novedad'.\n",
    "dash_dataset.loc[dash_dataset['Canal de Pago'].isna(), 'Tipo de Oferta']='Pago con Novedad'\n",
    "\n",
    "# Asignación tipo de oferta 'FOSFEC'.\n",
    "dash_dataset.loc[dash_dataset['Evento']=='fosfec', 'Tipo de Oferta'] = 'FOSFEC'\n",
    "\n",
    "# Asignación tipo de oferta 'Pago empresarial'.\n",
    "dash_dataset.loc[dash_dataset['Motivo de Cambio'].notna() & dash_dataset['Motivo de Cambio'].str.contains(pat_empresarial, case=False, regex=True), 'Tipo de Oferta'] = 'Pago Empresarial'\n",
    "\n",
    "# Asignación tipo de oferta 'Excedentes del 55%'.\n",
    "dash_dataset.loc[(dash_dataset['Ciclos'].str.contains(pat_exc55, case=False, regex=True)) | dash_dataset['Motivo de Cambio'].str.contains(pat_exc55, case=False, regex=True), 'Tipo de Oferta'] = 'Excedentes del 55%'\n",
    "\n",
    "# Asignación tipo de oferta 'Venta Directa'.\n",
    "dash_dataset.loc[(dash_dataset['Canal de Pago'].notna()) & (dash_dataset['Motivo de Cambio'].isna()), 'Tipo de Oferta'] = 'Venta Directa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de campos del portafolio que se usarán para cruzar con el reporte estadístico.\n",
    "fields_portafolio = [\n",
    "    'UNIDAD DE NEGOCIO',\n",
    "    'LINEA',\n",
    "    'CODIGO SAP',\n",
    "    'MATERIAL',\n",
    "    'NUM. PARTICIPANTES MAX',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75773/865904377.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# última versión del portafolio.\n",
    "portafolio = pd.read_excel(path_portafolio, usecols=fields_portafolio)\n",
    "\n",
    "# Archivo que contiene materiales pasados que no están en la última actualización del portafolio.\n",
    "past_portafolio = pd.read_excel(path_past_portafolio, usecols=fields_portafolio)\n",
    "\n",
    "full_portafolio=pd.concat([portafolio, past_portafolio])\n",
    "\n",
    "\n",
    "# Selecciona del portafolio sólo las filas donde la unidad de negocio coincida con las indicacadas en la lista 'UNIDADES DE NEGOCIO', pues son las unidades que ofertan servicios en Hércules.\n",
    "UNIDADES_NEGOCIO = ['EDUCACIÓN', 'CULTURA', 'ESPARCIMIENTO', 'DESARROLLO SOCIAL']\n",
    "portafolio_hercules = full_portafolio[\n",
    "     full_portafolio['UNIDAD DE NEGOCIO'].isin(UNIDADES_NEGOCIO)\n",
    "]\n",
    "\n",
    "# Elimina las fila donde se encuentre el repetido el código SAP.\n",
    "portafolio_hercules.drop_duplicates('CODIGO SAP', inplace=True, keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "portafolio_hercules.to_csv('full.csv', index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se ejecuta un left-join trayendo los campos de portafolio cruzados a través del Código SAP.\n",
    "final_dataset = pd.merge(\n",
    "    dash_dataset,\n",
    "    portafolio_hercules[\n",
    "        [\n",
    "            'UNIDAD DE NEGOCIO',\n",
    "            'LINEA',\n",
    "            'CODIGO SAP',\n",
    "            'NUM. PARTICIPANTES MAX',\n",
    "        ]\n",
    "    ],\n",
    "    left_on='Id Material',\n",
    "    right_on='CODIGO SAP',\n",
    "    how='left',\n",
    "    # validate='1:m'\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_dataset.to_csv('dash_dataset.csv', index = False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv('./assets/data/dash_dataset.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['Tipo de oferta'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/media/victor/info/victor/Insync/vmorenomarin@gmail.com/Google Drive/git/hercules_dash/data_clean.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/victor/info/victor/Insync/vmorenomarin%40gmail.com/Google%20Drive/git/hercules_dash/data_clean.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m final\u001b[39m=\u001b[39mfinal_dataset\u001b[39m.\u001b[39;49mgroupby(by\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mMes Registro\u001b[39;49m\u001b[39m\"\u001b[39;49m], as_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39;49mcount()\u001b[39m.\u001b[39;49mpivot(columns\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mTipo de oferta\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/victor/info/victor/Insync/vmorenomarin%40gmail.com/Google%20Drive/git/hercules_dash/data_clean.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m final\n",
      "File \u001b[0;32m/media/victor/info/victor/Insync/vmorenomarin@gmail.com/Google Drive/git/hercules_dash/venv/lib/python3.8/site-packages/pandas/core/frame.py:7882\u001b[0m, in \u001b[0;36mDataFrame.pivot\u001b[0;34m(self, index, columns, values)\u001b[0m\n\u001b[1;32m   7877\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   7878\u001b[0m \u001b[39m@Appender\u001b[39m(_shared_docs[\u001b[39m\"\u001b[39m\u001b[39mpivot\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   7879\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpivot\u001b[39m(\u001b[39mself\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, columns\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, values\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   7880\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpivot\u001b[39;00m \u001b[39mimport\u001b[39;00m pivot\n\u001b[0;32m-> 7882\u001b[0m     \u001b[39mreturn\u001b[39;00m pivot(\u001b[39mself\u001b[39;49m, index\u001b[39m=\u001b[39;49mindex, columns\u001b[39m=\u001b[39;49mcolumns, values\u001b[39m=\u001b[39;49mvalues)\n",
      "File \u001b[0;32m/media/victor/info/victor/Insync/vmorenomarin@gmail.com/Google Drive/git/hercules_dash/venv/lib/python3.8/site-packages/pandas/core/reshape/pivot.py:493\u001b[0m, in \u001b[0;36mpivot\u001b[0;34m(data, index, columns, values)\u001b[0m\n\u001b[1;32m    490\u001b[0m     append \u001b[39m=\u001b[39m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    491\u001b[0m     \u001b[39m# error: Unsupported operand types for + (\"List[Any]\" and \"ExtensionArray\")\u001b[39;00m\n\u001b[1;32m    492\u001b[0m     \u001b[39m# error: Unsupported left operand type for + (\"ExtensionArray\")\u001b[39;00m\n\u001b[0;32m--> 493\u001b[0m     indexed \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mset_index(\n\u001b[1;32m    494\u001b[0m         cols \u001b[39m+\u001b[39;49m columns_listlike, append\u001b[39m=\u001b[39;49mappend  \u001b[39m# type: ignore[operator]\u001b[39;49;00m\n\u001b[1;32m    495\u001b[0m     )\n\u001b[1;32m    496\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/media/victor/info/victor/Insync/vmorenomarin@gmail.com/Google Drive/git/hercules_dash/venv/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/media/victor/info/victor/Insync/vmorenomarin@gmail.com/Google Drive/git/hercules_dash/venv/lib/python3.8/site-packages/pandas/core/frame.py:5500\u001b[0m, in \u001b[0;36mDataFrame.set_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   5497\u001b[0m                 missing\u001b[39m.\u001b[39mappend(col)\n\u001b[1;32m   5499\u001b[0m \u001b[39mif\u001b[39;00m missing:\n\u001b[0;32m-> 5500\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of \u001b[39m\u001b[39m{\u001b[39;00mmissing\u001b[39m}\u001b[39;00m\u001b[39m are in the columns\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5502\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   5503\u001b[0m     frame \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['Tipo de oferta'] are in the columns\""
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "final=final_dataset.groupby(by=[\"Mes Registro\"], as_index=True).count().pivot(columns=[\"Tipo de oferta\"])\n",
    "final\n",
    "# final=final_dataset[[\"Tipo de Oferta\", \"Mes Registro\"]]\n",
    "# final.groupby(\"Mes Registro\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>FB</th>\n",
       "      <th>NFLX</th>\n",
       "      <th>MSFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>1.018172</td>\n",
       "      <td>1.011943</td>\n",
       "      <td>1.061881</td>\n",
       "      <td>0.959968</td>\n",
       "      <td>1.053526</td>\n",
       "      <td>1.015988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-15</td>\n",
       "      <td>1.032008</td>\n",
       "      <td>1.019771</td>\n",
       "      <td>1.053240</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>1.049860</td>\n",
       "      <td>1.020524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>1.066783</td>\n",
       "      <td>0.980057</td>\n",
       "      <td>1.140676</td>\n",
       "      <td>1.016858</td>\n",
       "      <td>1.307681</td>\n",
       "      <td>1.066561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>1.008773</td>\n",
       "      <td>0.917143</td>\n",
       "      <td>1.163374</td>\n",
       "      <td>1.018357</td>\n",
       "      <td>1.273537</td>\n",
       "      <td>1.040708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2019-12-02</td>\n",
       "      <td>1.216280</td>\n",
       "      <td>1.546914</td>\n",
       "      <td>1.425061</td>\n",
       "      <td>1.075997</td>\n",
       "      <td>1.463641</td>\n",
       "      <td>1.720717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2019-12-09</td>\n",
       "      <td>1.222821</td>\n",
       "      <td>1.572286</td>\n",
       "      <td>1.432660</td>\n",
       "      <td>1.038855</td>\n",
       "      <td>1.421496</td>\n",
       "      <td>1.752239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>1.224418</td>\n",
       "      <td>1.596800</td>\n",
       "      <td>1.453455</td>\n",
       "      <td>1.104094</td>\n",
       "      <td>1.604362</td>\n",
       "      <td>1.784896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>1.226504</td>\n",
       "      <td>1.656000</td>\n",
       "      <td>1.521226</td>\n",
       "      <td>1.113728</td>\n",
       "      <td>1.567170</td>\n",
       "      <td>1.802472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>1.213014</td>\n",
       "      <td>1.678000</td>\n",
       "      <td>1.503360</td>\n",
       "      <td>1.098475</td>\n",
       "      <td>1.540883</td>\n",
       "      <td>1.788185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date      GOOG      AAPL      AMZN        FB      NFLX      MSFT\n",
       "0    2018-01-01  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "1    2018-01-08  1.018172  1.011943  1.061881  0.959968  1.053526  1.015988\n",
       "2    2018-01-15  1.032008  1.019771  1.053240  0.970243  1.049860  1.020524\n",
       "3    2018-01-22  1.066783  0.980057  1.140676  1.016858  1.307681  1.066561\n",
       "4    2018-01-29  1.008773  0.917143  1.163374  1.018357  1.273537  1.040708\n",
       "..          ...       ...       ...       ...       ...       ...       ...\n",
       "100  2019-12-02  1.216280  1.546914  1.425061  1.075997  1.463641  1.720717\n",
       "101  2019-12-09  1.222821  1.572286  1.432660  1.038855  1.421496  1.752239\n",
       "102  2019-12-16  1.224418  1.596800  1.453455  1.104094  1.604362  1.784896\n",
       "103  2019-12-23  1.226504  1.656000  1.521226  1.113728  1.567170  1.802472\n",
       "104  2019-12-30  1.213014  1.678000  1.503360  1.098475  1.540883  1.788185\n",
       "\n",
       "[105 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "import plotly.express as px\n",
    "# figure=px.line(data, x=data.date, y=\"GOOG\")\n",
    "e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36310b98abd5b420301472a5a3e98f7c1c94199f7b2ab2a346c446c6c3453b59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
